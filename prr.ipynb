{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"prr.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"authorship_tag":"ABX9TyNH9KtVdNLw0Zat7UsDDiPW"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"wUWipCBeI3wV","colab_type":"code","colab":{}},"source":["\n","import pandas as pd\n","\n","import  pandas, re, os ,glob, sklearn \n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from collections import Counter\n","from bs4 import BeautifulSoup    \n","import numpy as np\n","\n","from nltk.corpus import stopwords \n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn import svm\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn import ensemble\n","import matplotlib.pyplot as plt\n","from sklearn.tree import DecisionTreeClassifier \n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.linear_model import PassiveAggressiveClassifier\n","from numpy import array\n","from sklearn.preprocessing import MinMaxScaler\n","from imblearn.over_sampling import RandomOverSampler,SMOTE\n","from sklearn import preprocessing \n","from sklearn . preprocessing import StandardScaler\n","from sklearn.cluster import DBSCAN\n","from sklearn import metrics\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import make_blobs\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Kids0OkI_Ks","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OnPmmfJ5JVuB","colab_type":"code","colab":{}},"source":["\n","\n","\n","'''\n","import citation_extractor\n","import refextract\n","from refextract import extract_journal_reference\n","\n","\n","reference = extract_journal_reference('J.Phys.,A39,13445')\n","'''\n","\n","\n","\n","\n","\n","\n","\n","def dbscan(X, eps, min_samples):\n","    ss = StandardScaler()\n","    X = ss.fit_transform(X)\n","    db = DBSCAN(eps=eps, min_samples=min_samples)\n","    db.fit(X)\n","    y_pred = db.fit_predict(X)\n","    labels = db.labels_\n","    print(len(labels))\n","    # for i in range(len(labels)):\n","    #     print(\"Demnision of labels:\"type(shape))\n","    #     print(\"lable data\",i)\n","\n","    cluster_values=np.where(labels==7)[0]\n","    print(cluster_values)\n","    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n","    n_noise_ = list(labels).count(-1)\n","    print (\"Number of cluster:\",n_clusters_)\n","    print(\"Number of noise:\" ,n_noise_)\n","    plt.scatter(X[:,0], X[:,1],c=y_pred, cmap='Paired')\n","    plt.title(\"DBSCAN\")\n","    plt.show()\n","\n","X = pd.read_csv('/content/drive/My Drive/Prr clustring/cit2.csv',sep=',')\n","#print X\n","#X=numpy.array(X)\n","#print X.reshape(1,-1)\n","#labels = db.labels_\n","\n","\n","\n","eps=0.3\n","min_samples=13\n","\n","dbscan(X, eps, min_samples)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rZplb0KRsz1h","colab_type":"code","colab":{}},"source":["data=pd.DataFrame()\n","data= pd.read_csv('/content/drive/My Drive/Prr clustring/dumy-data.csv',encoding= 'unicode_escape')\n","# print(data.set_index('index'))\n","index=data.set_index('index')\n","index=data['index']\n","index=index.astype(int)\n","# print(index+2)\n","# print(type(index))\n","lst=[5,3,4,8]\n","for i in  range(len(index)):\n","    for k in range(len(lst)):\n","        if index[i]==lst[k]:\n","           title=data['title'][k]\n","           print(title)\n","\n"],"execution_count":null,"outputs":[]}]}